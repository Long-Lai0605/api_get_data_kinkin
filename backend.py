import gspread
import requests
import pandas as pd
import math
import time
import toml
from datetime import datetime
from google.oauth2.service_account import Credentials
from concurrent.futures import ThreadPoolExecutor, as_completed

# --- C·∫§U H√åNH ---
SCOPE = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

def load_secrets_headless():
    try: return toml.load(".streamlit/secrets.toml")
    except: return None

def get_connection(secrets_dict):
    try:
        if not secrets_dict: return None, "Secrets is empty"
        creds = Credentials.from_service_account_info(secrets_dict["gcp_service_account"], scopes=SCOPE)
        gc = gspread.authorize(creds)
        master_id = secrets_dict["system"]["master_sheet_id"]
        return gc.open_by_key(master_id), "Success"
    except Exception as e: return None, str(e)

def init_database(secrets_dict):
    sh, msg = get_connection(secrets_dict)
    if not sh: return
    
    # C·∫≠p nh·∫≠t schema: Th√™m c·ªôt Filter Key
    schemas = {
        "luu_cau_hinh": ["Block Name", "Tr·∫°ng th√°i", "Ng√†y b·∫Øt ƒë·∫ßu", "Filter Key Start", "Ng√†y k·∫øt th√∫c", "Filter Key End", "Link ƒê√≠ch", "Sheet ƒê√≠ch", "Last Run", "Total Rows"],
        "log_api_1office": ["Block Name", "Method", "API URL", "Access Token (Encrypted)"],
        "log_chay_auto_github": ["Run ID", "Th·ªùi gian", "Status", "Message"]
    }
    
    existing = [s.title for s in sh.worksheets()]
    for name, cols in schemas.items():
        if name not in existing:
            try:
                wks = sh.add_worksheet(name, 100, 20)
                wks.append_row(cols)
            except: pass

# --- H√ÄM H·ªñ TR·ª¢ L·ªåC DATE (CLIENT-SIDE) ---
def parse_date(date_str):
    """Chuy·ªÉn ƒë·ªïi chu·ªói ng√†y t·ª´ 1Office (th∆∞·ªùng l√† dd/mm/yyyy ho·∫∑c yyyy-mm-dd) v·ªÅ datetime"""
    if not date_str: return None
    formats = ["%d/%m/%Y", "%Y-%m-%d", "%d-%m-%Y", "%Y/%m/%d", "%d/%m/%Y %H:%M:%S"]
    for fmt in formats:
        try:
            return datetime.strptime(str(date_str).split(' ')[0], fmt)
        except: continue
    return None

def filter_data_client_side(data, key_start, date_start, key_end, date_end):
    """L·ªçc d·ªØ li·ªáu d·ª±a tr√™n key ng∆∞·ªùi d√πng c·∫•u h√¨nh"""
    if not data: return []
    # N·∫øu kh√¥ng c·∫•u h√¨nh tr∆∞·ªùng l·ªçc th√¨ l·∫•y h·∫øt
    if not key_start and not key_end:
        return data

    filtered = []
    # Chuy·ªÉn ƒë·ªïi ng√†y c·∫•u h√¨nh (l√† object date c·ªßa python) sang datetime
    d_start = datetime.combine(date_start, datetime.min.time()) if date_start else None
    d_end = datetime.combine(date_end, datetime.max.time()) if date_end else None

    for item in data:
        is_valid = True
        
        # 1. Ki·ªÉm tra ng√†y b·∫Øt ƒë·∫ßu
        if key_start and d_start:
            val_str = item.get(key_start)
            val_date = parse_date(val_str)
            if not val_date or val_date < d_start:
                is_valid = False
        
        # 2. Ki·ªÉm tra ng√†y k·∫øt th√∫c
        if is_valid and key_end and d_end:
            val_str = item.get(key_end)
            val_date = parse_date(val_str)
            if not val_date or val_date > d_end:
                is_valid = False
                
        if is_valid:
            filtered.append(item)
            
    return filtered

# --- H√ÄM G·ªåI API 1 PAGE (D√ôNG CHO PARALLEL) ---
def fetch_single_page(url, params, method, page_num):
    p = params.copy()
    p["page"] = page_num
    try:
        if method.upper() == "POST":
            r = requests.post(url, params=p, json={}, timeout=30)
        else:
            r = requests.get(url, params=p, timeout=30)
        
        if r.status_code == 200:
            d = r.json()
            return d.get("data", d.get("items", []))
    except: pass
    return []

# --- MAIN FETCH (PARALLEL) ---
def fetch_1office_data_parallel(url, token, method="GET", status_callback=None):
    all_data = []
    limit = 100
    clean_token = str(token).strip()
    params = {"access_token": clean_token, "limit": limit}

    if status_callback: status_callback("üì° ƒêang g·ªçi Page 1 ƒë·ªÉ l·∫•y t·ªïng s·ªë...")

    # B∆Ø·ªöC 1: L·∫§Y PAGE 1
    try:
        if method.upper() == "POST":
            res = requests.post(url, params={**params, "page": 1}, json={}, timeout=30)
        else:
            res = requests.get(url, params={**params, "page": 1}, timeout=30)
            
        if res.status_code != 200: return None, f"HTTP {res.status_code}"
        d = res.json()
        if d.get("code") == "token_not_valid": return None, "H·∫øt h·∫°n API"
        
        total_items = d.get("total_item", 0)
        items = d.get("data", d.get("items", []))
        if items: all_data.extend(items)
        
        if total_items == 0: return [], "Success"

        # B∆Ø·ªöC 2: T√çNH TO√ÅN & CH·∫†Y SONG SONG
        total_pages = math.ceil(total_items / limit)
        
        if total_pages > 1:
            if status_callback: status_callback(f"üöÄ Ph√°t hi·ªán {total_pages} trang. ƒêang t·∫£i song song...")
            
            # S·ª≠ d·ª•ng ThreadPoolExecutor ƒë·ªÉ ch·∫°y song song (Max 5-10 threads ƒë·ªÉ tr√°nh s·∫≠p server)
            with ThreadPoolExecutor(max_workers=5) as executor:
                futures = {executor.submit(fetch_single_page, url, params, method, p): p for p in range(2, total_pages + 1)}
                
                completed_pages = 0
                for future in as_completed(futures):
                    page_items = future.result()
                    if page_items:
                        all_data.extend(page_items)
                    completed_pages += 1
                    # Update nh·∫π progress n·∫øu c·∫ßn
                    
        return all_data, "Success"
        
    except Exception as e:
        return None, str(e)

# --- GHI SHEET (TR·∫¢ V·ªÄ D·∫¢I D√íNG) ---
def write_to_sheet_range(secrets_dict, block_conf, data):
    if not data: return "0", "No Data"
    
    try:
        creds = Credentials.from_service_account_info(secrets_dict["gcp_service_account"], scopes=SCOPE)
        gc = gspread.authorize(creds)
        dest_ss = gc.open_by_url(block_conf['Link ƒê√≠ch'])
        wks_name = block_conf['Sheet ƒê√≠ch']
        
        try: wks = dest_ss.worksheet(wks_name)
        except: wks = dest_ss.add_worksheet(wks_name, 1000, 20)

        # T√≠nh to√°n d√≤ng b·∫Øt ƒë·∫ßu
        # N·∫øu sheet tr·ªëng (ch·ªâ c√≥ header ho·∫∑c ko), last_row l√† s·ªë d√≤ng c√≥ d·ªØ li·ªáu
        last_row_start = len(wks.get_all_values()) + 1 
            
        rows_add = []
        month = datetime.now().strftime("%m/%Y")
        b_name = block_conf['Block Name']
        
        for item in data:
            r = list(item.values())
            r = [str(x) if isinstance(x, (dict, list)) else x for x in r]
            r.extend([block_conf['Link ƒê√≠ch'], wks_name, month, b_name])
            rows_add.append(r)
            
        wks.append_rows(rows_add)
        
        # T√≠nh to√°n d√≤ng k·∫øt th√∫c
        last_row_end = last_row_start + len(rows_add) - 1
        range_str = f"D√≤ng {last_row_start} -> {last_row_end}"
        
        # C·∫≠p nh·∫≠t l·∫°i Master Sheet (Last Run & Total Rows)
        update_master_status(secrets_dict, b_name, range_str)
        
        return range_str, "Success"
        
    except Exception as e:
        return "0", f"Write Error: {e}"

def update_master_status(secrets_dict, block_name, range_str):
    """C·∫≠p nh·∫≠t tr·∫°ng th√°i ch·∫°y cu·ªëi v√†o Master Sheet"""
    try:
        sh, _ = get_connection(secrets_dict)
        wks = sh.worksheet("luu_cau_hinh")
        # T√¨m d√≤ng ch·ª©a block name
        cell = wks.find(block_name)
        if cell:
            # Last Run (C·ªôt 9), Total Rows (C·ªôt 10) - D·ª±a v√†o schema
            # Schema: Name, Status, Start, KeyStart, End, KeyEnd, Link, Sheet, LastRun, TotalRows
            now = datetime.now().strftime("%H:%M %d/%m")
            wks.update_cell(cell.row, 9, now) # Update Last Run
            wks.update_cell(cell.row, 10, range_str) # Update Total Rows
    except: pass

# --- GET BLOCKS ---
def get_active_blocks(secrets_dict):
    sh, _ = get_connection(secrets_dict)
    if not sh: return []
    try:
        c = pd.DataFrame(sh.worksheet("luu_cau_hinh").get_all_records())
        s = pd.DataFrame(sh.worksheet("log_api_1office").get_all_records())
        if c.empty or s.empty: return []
        
        c.columns = [x.strip() for x in c.columns]
        s.columns = [x.strip() for x in s.columns]
        
        # Fix missing columns if old schema
        for col in ["Filter Key Start", "Filter Key End"]:
            if col not in c.columns: c[col] = ""

        full = pd.merge(c, s, on="Block Name", how="left")
        
        # Reorder columns for DataFrame display preference
        # S·∫Øp x·∫øp l·∫°i c·ªôt ƒë·ªÉ hi·ªÉn th·ªã Dashboard
        display_cols = ["Block Name", "Tr·∫°ng th√°i", "Method", "API URL", "Access Token (Encrypted)", 
                        "Link ƒê√≠ch", "Sheet ƒê√≠ch", "Ng√†y b·∫Øt ƒë·∫ßu", "Ng√†y k·∫øt th√∫c", 
                        "Total Rows", "Last Run", "Filter Key Start", "Filter Key End"]
        
        # Ch·ªâ gi·ªØ l·∫°i c√°c c·ªôt c√≥ trong display_cols v√† t·ªìn t·∫°i trong full
        final_cols = [col for col in display_cols if col in full.columns]
        
        return full[final_cols].fillna("").to_dict('records')
    except: return []

def add_new_block(secrets_dict, name, method, url, token, link, sheet, start, key_start, end, key_end):
    sh, _ = get_connection(secrets_dict)
    if not sh: return False
    
    # L∆∞u ƒë√∫ng th·ª© t·ª± schema m·ªõi
    sh.worksheet("luu_cau_hinh").append_row([
        name, "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t", str(start), key_start, str(end), key_end, link, sheet, "", ""
    ])
    sh.worksheet("log_api_1office").append_row([name, method, url, token.strip()])
    return True
