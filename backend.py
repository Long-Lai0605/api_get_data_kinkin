import gspread
import requests
import pandas as pd
import math
import time
import toml
import json
from datetime import datetime
from google.oauth2.service_account import Credentials
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlencode, quote

# --- C·∫§U H√åNH ---
SCOPE = ["https://www.googleapis.com/auth/spreadsheets", "https://www.googleapis.com/auth/drive"]

def load_secrets_headless():
    try: return toml.load(".streamlit/secrets.toml")
    except: return None

def get_connection(secrets_dict):
    try:
        if not secrets_dict: return None, "Secrets is empty"
        creds = Credentials.from_service_account_info(secrets_dict["gcp_service_account"], scopes=SCOPE)
        gc = gspread.authorize(creds)
        master_id = secrets_dict["system"]["master_sheet_id"]
        return gc.open_by_key(master_id), "Success"
    except Exception as e: return None, str(e)

def init_database(secrets_dict):
    sh, msg = get_connection(secrets_dict)
    if not sh: return
    
    schemas = {
        "luu_cau_hinh": ["Block Name", "Tr·∫°ng th√°i", "Ng√†y b·∫Øt ƒë·∫ßu", "Ng√†y k·∫øt th√∫c", "Filter Key", "Link ƒê√≠ch", "Sheet ƒê√≠ch", "Last Run", "Total Rows"],
        "log_api_1office": ["Block Name", "Method", "API URL", "Access Token (Encrypted)"],
        "log_chay_auto_github": ["Run ID", "Th·ªùi gian", "Status", "Message"]
    }
    
    existing = [s.title for s in sh.worksheets()]
    for name, cols in schemas.items():
        if name not in existing:
            try:
                wks = sh.add_worksheet(name, 100, 20)
                wks.append_row(cols)
            except: pass

# --- [FIX QUAN TR·ªåNG] H√ÄM X·ª¨ L√ù NG√ÄY TH√ÅNG ƒêA D·∫†NG ---
def parse_date_val(date_str):
    """
    X·ª≠ l√Ω m·ªçi ƒë·ªãnh d·∫°ng ng√†y th√°ng:
    - 20/11/2025 17:00:00
    - 07/11/2025
    - 2025-11-20
    """
    if not date_str: return None
    s = str(date_str).strip()
    
    # Danh s√°ch c√°c format ph·ªï bi·∫øn c·ªßa 1Office
    formats = [
        "%d/%m/%Y %H:%M:%S", # D·∫°ng c√≥ gi·ªù: 20/11/2025 17:00:00
        "%d/%m/%Y",          # D·∫°ng ng·∫Øn: 07/11/2025
        "%Y-%m-%d %H:%M:%S", # D·∫°ng chu·∫©n DB: 2025-11-20 17:00:00
        "%Y-%m-%d",          # D·∫°ng chu·∫©n ng·∫Øn: 2025-11-20
        "%d-%m-%Y"           # D·∫°ng g·∫°ch ngang: 20-11-2025
    ]
    
    for fmt in formats:
        try:
            return datetime.strptime(s, fmt)
        except: continue
        
    # N·∫øu th·ª≠ c√°c ki·ªÉu tr√™n v·∫´n l·ªói, th·ª≠ c·∫Øt chu·ªói l·∫•y ph·∫ßn ƒë·∫ßu (d√†nh cho c√°c case l·∫°)
    try:
        # C·ªë g·∫Øng c·ª©u d·ªØ li·ªáu b·∫±ng c√°ch l·∫•y ph·∫ßn ng√†y tr∆∞·ªõc d·∫•u c√°ch
        return datetime.strptime(s.split(' ')[0], "%d/%m/%Y")
    except: pass
    
    return None

def filter_chunk_client_side(items, filter_key, date_start, date_end):
    """
    L·ªõp b·∫£o v·ªá 2: L·ªçc l·∫°i d·ªØ li·ªáu.
    QUAN TR·ªåNG: N·∫øu kh√¥ng parse ƒë∆∞·ª£c ng√†y -> M·∫∑c ƒë·ªãnh GI·ªÆ L·∫†I (Fail-open) ƒë·ªÉ tr√°nh m·∫•t d·ªØ li·ªáu.
    """
    if not filter_key or (not date_start and not date_end):
        return items
        
    filtered = []
    # date_start/end ·ªü ƒë√¢y l√† object date, c·∫ßn chuy·ªÉn sang datetime ƒë·ªÉ so s√°nh
    d_start = datetime.combine(date_start, datetime.min.time()) if date_start else None
    d_end = datetime.combine(date_end, datetime.max.time()) if date_end else None # 23:59:59

    for item in items:
        val_str = item.get(filter_key)
        
        # N·∫øu kh√¥ng c√≥ gi√° tr·ªã key n√†y, coi nh∆∞ kh√¥ng th·ªèa m√£n -> B·ªè qua
        if not val_str: 
            continue

        val_date = parse_date_val(val_str)
        
        # [AN TO√ÄN] N·∫øu c√≥ d·ªØ li·ªáu ng√†y nh∆∞ng format l·∫° qu√° kh√¥ng ƒë·ªçc ƒë∆∞·ª£c
        # -> GI·ªÆ L·∫†I ƒë·ªÉ ng∆∞·ªùi d√πng ki·ªÉm tra th·ªß c√¥ng, th√† th·ª´a h∆°n thi·∫øu.
        if not val_date: 
            filtered.append(item)
            continue

        # So s√°nh logic
        if d_start and val_date < d_start: continue
        if d_end and val_date > d_end: continue
        
        filtered.append(item)
    return filtered

# --- H√ÄM D·ª∞NG URL ---
def build_manual_url(base_url, access_token, limit, page, filters_dict=None):
    params = {
        "access_token": access_token.strip(),
        "limit": limit,
        "page": page
    }
    query_string = urlencode(params)
    filter_part = ""
    if filters_dict:
        json_str = json.dumps(filters_dict, separators=(',', ':'))
        encoded_json = quote(json_str)
        filter_part = f"&filters={encoded_json}"
    return f"{base_url}?{query_string}{filter_part}"

def fetch_single_page_manual(full_url, method):
    try:
        if method.upper() == "POST":
            r = requests.post(full_url, json={}, timeout=30)
        else:
            r = requests.get(full_url, timeout=30)
        if r.status_code == 200:
            d = r.json()
            return d.get("data", d.get("items", []))
    except: pass
    return []

# --- H√ÄM FETCH TH√îNG MINH (K√çCH HO·∫†T L·∫†I L·ªåC CLIENT) ---
def fetch_1office_data_smart(url, token, method="GET", filter_key=None, date_start=None, date_end=None, status_callback=None):
    all_data = []
    limit = 100
    
    # 1. B·ªô l·ªçc Server (V·∫´n g·ª≠i ƒë·ªÉ hi v·ªçng Server l·ªçc b·ªõt ƒë∆∞·ª£c t√≠ n√†o hay t√≠ ƒë√≥)
    filters_dict = None
    if filter_key and (date_start or date_end):
        filters_dict = {}
        if date_start: filters_dict[f"{filter_key}_from"] = date_start.strftime("%Y-%m-%d")
        if date_end: filters_dict[f"{filter_key}_to"] = date_end.strftime("%Y-%m-%d")
        
        if status_callback:
            status_callback(f"üéØ Filter: {json.dumps(filters_dict)}")

    if status_callback: status_callback("üì° G·ªçi Page 1...")

    page1_url = build_manual_url(url, token, limit, 1, filters_dict)
    
    try:
        if method.upper() == "POST":
            res = requests.post(page1_url, json={}, timeout=30)
        else:
            res = requests.get(page1_url, timeout=30)
            
        if res.status_code != 200: return None, f"HTTP {res.status_code}"
        d = res.json()
        if d.get("code") == "token_not_valid": return None, "H·∫øt h·∫°n API"
        
        total_items = d.get("total_item", 0)
        items = d.get("data", d.get("items", []))
        
        # [K√çCH HO·∫†T L·∫†I] L·ªçc Client-side v·ªõi h√†m parse th√¥ng minh
        if items:
            clean_items = filter_chunk_client_side(items, filter_key, date_start, date_end)
            all_data.extend(clean_items)
        
        if total_items == 0: return [], "Success (0 KQ)"

        total_pages = math.ceil(total_items / limit)
        
        if total_pages > 1:
            if status_callback: 
                status_callback(f"üöÄ Server tr·∫£ {total_items} d√≤ng. ƒêang t·∫£i & L·ªçc k·ªπ...")
            
            with ThreadPoolExecutor(max_workers=10) as executor:
                futures = {}
                for p in range(2, total_pages + 1):
                    p_url = build_manual_url(url, token, limit, p, filters_dict)
                    futures[executor.submit(fetch_single_page_manual, p_url, method)] = p
                    
                for future in as_completed(futures):
                    page_items = future.result()
                    if page_items:
                        # [K√çCH HO·∫†T L·∫†I] L·ªçc t·ª´ng trang con
                        clean_chunk = filter_chunk_client_side(page_items, filter_key, date_start, date_end)
                        all_data.extend(clean_chunk)
                    
        return all_data, "Success"
        
    except Exception as e:
        return None, str(e)

# --- H√ÄM GHI SHEET (GHI ƒê√à / OVERWRITE) ---
def write_to_sheet_range(secrets_dict, block_conf, data):
    if not data: return "0", "No Data"
    try:
        creds = Credentials.from_service_account_info(secrets_dict["gcp_service_account"], scopes=SCOPE)
        gc = gspread.authorize(creds)
        dest_ss = gc.open_by_url(block_conf['Link ƒê√≠ch'])
        wks_name = block_conf['Sheet ƒê√≠ch']
        try: wks = dest_ss.worksheet(wks_name)
        except: wks = dest_ss.add_worksheet(wks_name, 1000, 20)

        # 1. X√ìA D·ªÆ LI·ªÜU C≈®
        wks.clear()

        rows_to_write = []
        
        # 2. T·∫†O HEADER
        first_item = data[0]
        api_headers = list(first_item.keys())
        system_headers = ["Link Ngu·ªìn", "Sheet Ngu·ªìn", "Th√°ng Ch·ªët", "Lu·ªìng (Block)"]
        rows_to_write.append(api_headers + system_headers)

        month = datetime.now().strftime("%m/%Y")
        b_name = block_conf['Block Name']
        
        # 3. CHU·∫®N B·ªä DATA
        for item in data:
            r = [item.get(k, "") for k in api_headers]
            r = [str(x) if isinstance(x, (dict, list)) else x for x in r]
            r.extend([block_conf['Link ƒê√≠ch'], wks_name, month, b_name])
            rows_to_write.append(r)
            
        # 4. GHI M·ªöI
        wks.update(values=rows_to_write, range_name='A1')
        
        range_str = f"L√†m m·ªõi {len(data)} d√≤ng"
        update_master_status(secrets_dict, b_name, range_str)
        return range_str, "Success"
    except Exception as e:
        return "0", f"Write Error: {e}"

def update_master_status(secrets_dict, block_name, range_str):
    try:
        sh, _ = get_connection(secrets_dict)
        wks = sh.worksheet("luu_cau_hinh")
        cell = wks.find(block_name)
        if cell:
            now = datetime.now().strftime("%H:%M %d/%m")
            wks.update_cell(cell.row, 8, now)
            wks.update_cell(cell.row, 9, range_str)
    except: pass

def get_active_blocks(secrets_dict):
    sh, _ = get_connection(secrets_dict)
    if not sh: return []
    try:
        c = pd.DataFrame(sh.worksheet("luu_cau_hinh").get_all_records())
        s = pd.DataFrame(sh.worksheet("log_api_1office").get_all_records())
        if c.empty or s.empty: return []
        c.columns = [x.strip() for x in c.columns]
        s.columns = [x.strip() for x in s.columns]
        if "Filter Key" not in c.columns: c["Filter Key"] = ""
        full = pd.merge(c, s, on="Block Name", how="left")
        display_cols = ["Block Name", "Tr·∫°ng th√°i", "Method", "API URL", "Access Token (Encrypted)", 
                        "Link ƒê√≠ch", "Sheet ƒê√≠ch", "Ng√†y b·∫Øt ƒë·∫ßu", "Ng√†y k·∫øt th√∫c", "Filter Key",
                        "Total Rows", "Last Run"]
        final_cols = [col for col in display_cols if col in full.columns]
        return full[final_cols].fillna("").to_dict('records')
    except: return []

def add_new_block(secrets_dict, name, method, url, token, link, sheet, start, end, filter_key):
    sh, _ = get_connection(secrets_dict)
    if not sh: return False
    sh.worksheet("luu_cau_hinh").append_row([
        name, "Ch∆∞a ch·ªët & ƒëang c·∫≠p nh·∫≠t", str(start), str(end), filter_key, link, sheet, "", ""
    ])
    sh.worksheet("log_api_1office").append_row([name, method, url, token.strip()])
    return True
